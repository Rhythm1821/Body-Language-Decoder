{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Import depencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic.HAND_CONNECTIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Make detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # Make detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=1,circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=1,circle_radius=1))\n",
    "\n",
    "        # 2. Left hand landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=2,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=2,circle_radius=2))\n",
    "\n",
    "        # 3. Right hand landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=2,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=2,circle_radius=2))\n",
    "\n",
    "        # 4. Pose detection\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=2,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=2,circle_radius=2))\n",
    "\n",
    "        cv2.imshow(\"Holistic model detection\",image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Capture landmarks and Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark) + len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1,num_coords+1):\n",
    "    landmarks+=[f\"x{val}, y{val}, z{val}, v{val}\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('coords.csv',mode=\"w\",newline=\"\") as f:\n",
    "    csv_writer = csv.writer(f,delimiter=\",\",quotechar=\"'\",quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"Victorius\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor feed\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        # Make detections\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        image.flags.writeable=True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.face_landmarks,mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=1,circle_radius=1),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=1,circle_radius=1))\n",
    "\n",
    "        # 2. Left hand landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=2,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=2,circle_radius=2))\n",
    "\n",
    "        # 3. Right hand landmarks\n",
    "        mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=2,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=2,circle_radius=2))\n",
    "\n",
    "        # 4. Pose detection\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(255,0,0),thickness=2,circle_radius=2),\n",
    "                              mp_drawing.DrawingSpec(color=(240,0,0),thickness=2,circle_radius=2))\n",
    "        \n",
    "        # Export coordinates\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "            # Extract face landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x,landmark.y,landmark.z,landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "            # Concat rows\n",
    "            row = pose_row+face_row\n",
    "\n",
    "            # Insert row\n",
    "            row.insert(0,class_name)\n",
    "\n",
    "            # Export to csv\n",
    "            with open('coords.csv',mode='a',newline='') as f:\n",
    "                csv_writer = csv.writer(f,delimiter=\",\",quotechar=\"'\",quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        cv2.imshow(\"Holistic model detection\",image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Train custom model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Read in collected data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>'x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1'</th>\n",
       "      <th>'x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2'</th>\n",
       "      <th>'x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499'</th>\n",
       "      <th>'x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500'</th>\n",
       "      <th>'x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.597149</td>\n",
       "      <td>0.267684</td>\n",
       "      <td>-1.323826</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.631975</td>\n",
       "      <td>0.196773</td>\n",
       "      <td>-1.302478</td>\n",
       "      <td>0.999670</td>\n",
       "      <td>0.653470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.654806</td>\n",
       "      <td>0.184508</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.659594</td>\n",
       "      <td>0.177332</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.554802</td>\n",
       "      <td>0.296743</td>\n",
       "      <td>-0.583323</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.570428</td>\n",
       "      <td>0.250504</td>\n",
       "      <td>-0.539060</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.583454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600070</td>\n",
       "      <td>0.241152</td>\n",
       "      <td>0.012137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603935</td>\n",
       "      <td>0.235614</td>\n",
       "      <td>0.013085</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Victorius</td>\n",
       "      <td>0.552861</td>\n",
       "      <td>0.335191</td>\n",
       "      <td>-0.444129</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.566966</td>\n",
       "      <td>0.307970</td>\n",
       "      <td>-0.357046</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>0.576137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.593748</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.596545</td>\n",
       "      <td>0.319461</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Happy</td>\n",
       "      <td>0.555153</td>\n",
       "      <td>0.298754</td>\n",
       "      <td>-0.576781</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.571414</td>\n",
       "      <td>0.252038</td>\n",
       "      <td>-0.533597</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.584845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.601112</td>\n",
       "      <td>0.243528</td>\n",
       "      <td>0.010080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.604873</td>\n",
       "      <td>0.238695</td>\n",
       "      <td>0.010849</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Sad</td>\n",
       "      <td>0.575909</td>\n",
       "      <td>0.199637</td>\n",
       "      <td>-0.949337</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.590780</td>\n",
       "      <td>0.154384</td>\n",
       "      <td>-0.886057</td>\n",
       "      <td>0.999840</td>\n",
       "      <td>0.601955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618516</td>\n",
       "      <td>0.162212</td>\n",
       "      <td>0.031739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.622815</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.033156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class       'x1        y1        z1       v1'       'x2        y2  \\\n",
       "382        Sad  0.597149  0.267684 -1.323826  0.999840  0.631975  0.196773   \n",
       "109      Happy  0.554802  0.296743 -0.583323  0.999993  0.570428  0.250504   \n",
       "525  Victorius  0.552861  0.335191 -0.444129  0.999996  0.566966  0.307970   \n",
       "111      Happy  0.555153  0.298754 -0.576781  0.999993  0.571414  0.252038   \n",
       "338        Sad  0.575909  0.199637 -0.949337  0.999903  0.590780  0.154384   \n",
       "\n",
       "           z2       v2'       'x3  ...      z499   v499'     'x500      y500  \\\n",
       "382 -1.302478  0.999670  0.653470  ... -0.011770     0.0  0.654806  0.184508   \n",
       "109 -0.539060  0.999988  0.583454  ... -0.003003     0.0  0.600070  0.241152   \n",
       "525 -0.357046  0.999990  0.576137  ...  0.008749     0.0  0.593748  0.322887   \n",
       "111 -0.533597  0.999988  0.584845  ... -0.004757     0.0  0.601112  0.243528   \n",
       "338 -0.886057  0.999840  0.601955  ...  0.013312     0.0  0.618516  0.162212   \n",
       "\n",
       "         z500   v500'     'x501      y501      z501   v501'  \n",
       "382  0.007915     0.0  0.659594  0.177332  0.008632     0.0  \n",
       "109  0.012137     0.0  0.603935  0.235614  0.013085     0.0  \n",
       "525  0.026123     0.0  0.596545  0.319461  0.027483     0.0  \n",
       "111  0.010080     0.0  0.604873  0.238695  0.010849     0.0  \n",
       "338  0.031739     0.0  0.622815  0.155894  0.033156     0.0  \n",
       "\n",
       "[5 rows x 2005 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('coords.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train machine learning classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    \"lr\":make_pipeline(StandardScaler(),LogisticRegression()),\n",
    "    \"rc\":make_pipeline(StandardScaler(),RidgeClassifier()),\n",
    "    \"rf\":make_pipeline(StandardScaler(),RandomForestClassifier()),\n",
    "    \"gb\":make_pipeline(StandardScaler(),GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pipelines.values())[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
